{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Translation of time series into SAX representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the time series $x(t):=-3t^2+10$, for all $t\\geq0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time series x(t):=-3t^2+10\n",
    "def x(t):\n",
    "    assert np.greater_equal(t,0).all()\n",
    "    return -3*t^2+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then obtain the first $20$ elements $X:=[x(0),\\dots,x(19)]$ of this series and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = x(np.arange(20))\n",
    "ts_normalized = stats.zscore(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, the dimensionality of the normalized seris is reduced using $w$-dimensional piecewise aggregate approximation (PAA). Specifically, we use a dimension of $w=10$, thus averaging over 2 points in each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate w-dimensional PAA of a time series ts\n",
    "def calc_paa(ts, w):\n",
    "    n = len(ts)\n",
    "    mesh = np.arange(n * w)\n",
    "    index_out = mesh // n\n",
    "    index_in = mesh // w\n",
    "    _, n_rep = np.unique(index_out, return_counts=True)\n",
    "    res = np.array([ts[indices].sum() / n for indices in \n",
    "           np.split(index_in, n_rep.cumsum())[:-1]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38207347,  1.07494603,  1.17732185,  0.05118791,  0.15356372,\n",
       "       -0.15356372, -0.87019441, -0.35831534, -1.07494603, -1.38207347])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate PAA of length w=10, i.e., averaged over 2 points in each frame\n",
    "ts_paa = calc_paa(ts_normalized, 10)\n",
    "ts_paa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step consists in mapping each element of the PAA to a SAX symbol. We represent SAX symbols with the Roman alphabet, where the first letter corresponds to the lowest region, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function which maps each element of PAA to a sax-symbol, using n_breaks breakpoints\n",
    "def map_symbol(x, n_breaks):\n",
    "    symbols = list(string.ascii_lowercase[:n_breaks])\n",
    "    breaks = stats.norm.ppf(np.linspace(0, 1, n_breaks+1))\n",
    "    s = ''\n",
    "    for i in range(n_breaks):\n",
    "        if breaks[i] <= x < breaks[i+1]:\n",
    "            s = symbols[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a SAX cardinality of 4 yields the following symbolic SAX representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'd', 'd', 'c', 'c', 'b', 'a', 'b', 'a', 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain sax representation of the series\n",
    "ts_sax = [map_symbol(x,4) for x in ts_paa]\n",
    "ts_sax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the frequencies are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d 3\n",
      "c 2\n",
      "b 2\n",
      "a 3\n"
     ]
    }
   ],
   "source": [
    "# compute frequency\n",
    "for k,v in Counter(ts_sax).items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Exploring impact of parameters via graphical interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we provide a graphical interface to evaluate the impact of the PAA dimension and the SAX cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-dash in /opt/anaconda3/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: ansi2html in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (1.6.0)\n",
      "Requirement already satisfied: dash in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (1.19.0)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (5.1.4)\n",
      "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (1.1.2)\n",
      "Requirement already satisfied: retrying in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (1.3.3)\n",
      "Requirement already satisfied: ipython in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (7.13.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-dash) (2.23.0)\n",
      "Requirement already satisfied: dash-html-components==1.1.2 in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (1.1.2)\n",
      "Requirement already satisfied: dash-renderer==1.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (1.9.0)\n",
      "Requirement already satisfied: dash-table==4.11.2 in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (4.11.2)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (0.18.2)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (4.14.3)\n",
      "Requirement already satisfied: flask-compress in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (1.9.0)\n",
      "Requirement already satisfied: dash-core-components==1.15.0 in /opt/anaconda3/lib/python3.7/site-packages (from dash->jupyter-dash) (1.15.0)\n",
      "Requirement already satisfied: appnope; platform_system == \"Darwin\" in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (0.1.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (6.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (6.0.4)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter-dash) (4.3.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/anaconda3/lib/python3.7/site-packages (from flask->jupyter-dash) (2.11.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/anaconda3/lib/python3.7/site-packages (from flask->jupyter-dash) (7.1.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/anaconda3/lib/python3.7/site-packages (from flask->jupyter-dash) (1.0.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/anaconda3/lib/python3.7/site-packages (from flask->jupyter-dash) (1.1.0)\n",
      "Requirement already satisfied: six>=1.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from retrying->jupyter-dash) (1.14.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (3.0.4)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.15.2)\n",
      "Requirement already satisfied: backcall in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.1.0)\n",
      "Requirement already satisfied: pygments in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (46.1.3.post20200330)\n",
      "Requirement already satisfied: pickleshare in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-dash) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->jupyter-dash) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->jupyter-dash) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->jupyter-dash) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->jupyter-dash) (3.0.4)\n",
      "Requirement already satisfied: brotli in /opt/anaconda3/lib/python3.7/site-packages (from flask-compress->dash->jupyter-dash) (1.0.9)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (18.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash) (4.6.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/lib/python3.7/site-packages (from traitlets>=4.1.0->ipykernel->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (1.1.1)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.1.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-dash) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->jupyter-dash) (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter-dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the visualization, run the following cell. Subsequently, the parameters can be modified interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8055/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1a99ccd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='graph-with-slider'),\n",
    "    html.Label('PAA Dimension'),    \n",
    "    dcc.Slider(\n",
    "        id='paa-dim-slider',\n",
    "        min=2,\n",
    "        max=10,\n",
    "        value=10,\n",
    "        marks={str(i): str(i) for i in range(2,21)},\n",
    "        step=None\n",
    "    ),\n",
    "    html.Label('SAX Cardinality'),\n",
    "    dcc.Slider(\n",
    "        id='sax-cardinality-slider',\n",
    "        min=2,\n",
    "        max=8,\n",
    "        value=4,\n",
    "        marks={str(i): str(i) for i in range(2,21)},\n",
    "        step=None\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph-with-slider', 'figure'),\n",
    "    Input('paa-dim-slider', 'value'),\n",
    "    Input('sax-cardinality-slider', 'value'))\n",
    "def update_graph(paa_dim, sax_cardinality):\n",
    "    ts_paa = calc_paa(ts_normalized, paa_dim)\n",
    "    ts_sax = '' \n",
    "    for x in ts_paa:\n",
    "        ts_sax+=map_symbol(x,sax_cardinality)\n",
    "    breaks = stats.norm.ppf(np.linspace(0, 1, sax_cardinality+1))\n",
    "\n",
    "    x_normalized = np.linspace(0, 19, 20)\n",
    "    x_min = x_normalized[0]\n",
    "    x_max = x_normalized[-1]       \n",
    "    y_min = min(ts_normalized)\n",
    "    y_max = max(ts_normalized)\n",
    "    m = len(ts_normalized)/paa_dim\n",
    "    \n",
    "    breaks[0] = y_min-1\n",
    "    breaks[-1] = y_max+1\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        mode='lines+markers',\n",
    "        x=x_normalized, \n",
    "        y=ts_normalized, \n",
    "        name=\"Normalized Time Series\"\n",
    "    ))\n",
    "        \n",
    "    fig.update_xaxes(title_text=\"t\", range=[x_min-1, x_max+1])\n",
    "    fig.update_yaxes(range=[y_min-1, y_max+1], )\n",
    "    \n",
    "    fig.update_layout(margin=dict(l=150,t=10))\n",
    "    \n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                            x=x_max-6,\n",
    "                            y=y_max+0.5,\n",
    "                            showarrow=False,\n",
    "                            text='SAX Representation: '+ts_sax,\n",
    "                            textangle=0,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"y\",\n",
    "                            bordercolor=\"#F8F8F8\",\n",
    "                            borderwidth=2,\n",
    "                            borderpad=4,\n",
    "                            bgcolor=\"#F8F8F8\",\n",
    "                            opacity=0.8\n",
    "                           ))\n",
    "\n",
    "    for i,y_i in enumerate(ts_paa):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            mode='lines',\n",
    "            x=[i*m,(i+1)*m-1],\n",
    "            y=[y_i,y_i], \n",
    "            line_color=\"green\", \n",
    "            line_width=2,\n",
    "            name='Piecewise Aggregate Approximation (PAA)',\n",
    "            showlegend=True if i==0 else False,\n",
    "            legendgroup=1\n",
    "        ))\n",
    "        \n",
    "    for i in range(sax_cardinality):\n",
    "        if i>0:\n",
    "            fig.add_hline(\n",
    "                y=breaks[i],\n",
    "                line_width=1, line_dash=\"dash\", line_color=\"red\"\n",
    "            )\n",
    "        fig.add_annotation(dict(font=dict(color=\"red\",size=14),\n",
    "                        x=-0.1,\n",
    "                        y=(breaks[i]+breaks[i+1])/2,\n",
    "                        showarrow=False,\n",
    "                        text=string.ascii_lowercase[i],\n",
    "                        textangle=0,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"y\"\n",
    "                       ))\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n",
    "app.run_server(mode='inline', port=8055)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tHow to measure the quality of a machine learning model:\n",
    "    - Define a suitable metric. For instance, classification tasks are often evaluated by calculating the share of correct classifications (i.e., accuracy), whereas regression tasks often employ the (root) mean squared error. The choice of the metric is important and depends on multiple factors. Besides the task type (e.g. classification/regression) the decision can be determined by specific characteristics of the problem. For instance, if there is a high cost of misclassification associated with a specific scenario, standard metrics, such as accuracy, might not be suitable to evaluate model performance. An instructive example often mentioned is misclassifying an ill person as healthy, which is much more detrimental than misclassifying a healthy person. \n",
    "    - Usually, the dataset is split into training, test and development set. In most scenarios, assignment to the respective sets occurs at random. There are, however, expections; for instance, in time series analysis the training set usually precedes test and development sets. A model is trained on the training set, while the development set is used to measure the impact of different hyperparameters. The hyperparameters of the final model are chosen based on the development score. The test set is used to estimate the generalization capacity of the final model; it must only be employed after the final model has been selected. Subsequently, the final model is usually re-trained on the full dataset. Note that the estimation of the generalization capacity underlies the assumption that the distribution on new data will be the same as on the seen data.\n",
    "    - When calculating scores on development and test sets, the associated estimators can have a high variance. Therefore, in practice one often uses methods such as k-fold cross validation, in which the dataset is split into k equally sized sets and scores are obtained separately on each set. By subsequently averaging across all sets, the variance is reduced. The larger k, the less biased the results, but the higher the variance becomes; a good tradeoff often used in practice is k=10. When there are both test and development sets, the described method is performed as a nested loop over both dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to proceed if the model is below expectation:\n",
    "    - If development results are below expectation, then different hyperparameters or even different models should be considered.\n",
    "    - If test set results are below expectation, modifying the hyperparameters or selecting a better model until test set results meet expectations will result in an optimistically biased estimate of model performance. Therefore, model selection and hyperparameter tuning must occur prior to obtaining the test set results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
